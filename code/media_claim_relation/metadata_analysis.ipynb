{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe911c2",
   "metadata": {},
   "source": [
    "# Metadata Analysis and Category Similarity Study\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea234ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afc836",
   "metadata": {},
   "source": [
    "## Metadata Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5a0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_metadata_distribution():\n",
    "    \"\"\"\n",
    "    Analyze the distribution of metadata features across different categories\n",
    "    to understand why the enhanced text approach failed to distinguish between\n",
    "    slanted and unreliable source content.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Metadata Feature Distribution Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load enhanced dataset\n",
    "    enhanced_df = pd.read_csv(\"enhanced_dataset/training_ready_dataset.csv\")\n",
    "    \n",
    "    # Define metadata features\n",
    "    metadata_features = [\n",
    "        \"meta_misleadingUnverifiedClaimAsFact\",\n",
    "        \"meta_misleadingMissingImportantContext\", \n",
    "        \"meta_misleadingFactualError\",\n",
    "        \"meta_misleadingOutdatedInformation\",\n",
    "        \"meta_misleadingManipulatedMedia\",\n",
    "        \"meta_misleadingSatire\"\n",
    "    ]\n",
    "    \n",
    "    # Analyze overall feature distribution\n",
    "    results = {\n",
    "        'overall_distribution': {},\n",
    "        'category_analysis': {},\n",
    "        'signal_overlap': {}\n",
    "    }\n",
    "    \n",
    "    print(\"Overall Metadata Feature Distribution:\")\n",
    "    for feature in metadata_features:\n",
    "        if feature in enhanced_df.columns:\n",
    "            values = enhanced_df[feature].value_counts()\n",
    "            results['overall_distribution'][feature] = dict(values)\n",
    "            active_count = values.get(1.0, 0)\n",
    "            total_count = len(enhanced_df)\n",
    "            percentage = (active_count / total_count) * 100\n",
    "            print(f\"  {feature}: {active_count}/{total_count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nCategory-specific Analysis:\")\n",
    "    \n",
    "    # Analyze by category/label\n",
    "    for label in enhanced_df['label'].unique():\n",
    "        label_df = enhanced_df[enhanced_df['label'] == label]\n",
    "        results['category_analysis'][label] = {\n",
    "            'sample_count': len(label_df),\n",
    "            'feature_rates': {}\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{label} (n={len(label_df)}):\")\n",
    "        \n",
    "        for feature in metadata_features:\n",
    "            if feature in enhanced_df.columns:\n",
    "                active_count = (label_df[feature] == 1.0).sum()\n",
    "                rate = (active_count / len(label_df)) * 100\n",
    "                results['category_analysis'][label]['feature_rates'][feature] = {\n",
    "                    'count': int(active_count),\n",
    "                    'rate': round(rate, 1)\n",
    "                }\n",
    "                \n",
    "                feature_short = feature.replace('meta_misleading', '')\n",
    "                print(f\"  {feature_short}: {active_count}/{len(label_df)} ({rate:.1f}%)\")\n",
    "    \n",
    "    # Calculate overlap between slanted and unreliable source\n",
    "    if 'slanted' in enhanced_df['label'].str.lower().values and 'unreliable source' in enhanced_df['label'].str.lower().values:\n",
    "        slanted_df = enhanced_df[enhanced_df['label'].str.lower() == 'slanted']\n",
    "        unreliable_df = enhanced_df[enhanced_df['label'].str.lower() == 'unreliable source']\n",
    "        \n",
    "        print(f\"\\nOverlap Analysis: Slanted vs Unreliable Source\")\n",
    "        for feature in metadata_features:\n",
    "            if feature in enhanced_df.columns:\n",
    "                slanted_rate = (slanted_df[feature] == 1.0).mean() * 100\n",
    "                unreliable_rate = (unreliable_df[feature] == 1.0).mean() * 100\n",
    "                overlap = min(slanted_rate, unreliable_rate)\n",
    "                \n",
    "                feature_short = feature.replace('meta_misleading', '')\n",
    "                results['signal_overlap'][feature] = {\n",
    "                    'slanted_rate': round(slanted_rate, 1),\n",
    "                    'unreliable_rate': round(unreliable_rate, 1),\n",
    "                    'overlap_score': round(overlap, 1)\n",
    "                }\n",
    "                \n",
    "                print(f\"  {feature_short}:\")\n",
    "                print(f\"    Slanted: {slanted_rate:.1f}% | Unreliable: {unreliable_rate:.1f}% | Overlap: {overlap:.1f}%\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7fce1",
   "metadata": {},
   "source": [
    "## Similarity Analysis Between Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302ebeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_examples():\n",
    "    \"\"\"\n",
    "    Find the most similar examples between slanted and unreliable source categories\n",
    "    based on metadata feature vectors to demonstrate why classification failed.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nSimilarity Analysis: Slanted vs Unreliable Source\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load enhanced dataset\n",
    "    df = pd.read_csv(\"enhanced_dataset/enhanced_dataset.csv\")\n",
    "    \n",
    "    # Filter for slanted and unreliable source with metadata\n",
    "    slanted = df[(df['label'].str.lower() == 'slanted') & (df['has_metadata'] == True)].copy()\n",
    "    unreliable = df[(df['label'].str.lower() == 'unreliable source') & (df['has_metadata'] == True)].copy()\n",
    "    \n",
    "    print(f\"Analyzing {len(slanted)} slanted vs {len(unreliable)} unreliable source examples\")\n",
    "    \n",
    "    if len(slanted) == 0 or len(unreliable) == 0:\n",
    "        print(\"Insufficient examples for similarity analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Get metadata columns\n",
    "    metadata_cols = [col for col in df.columns if col.startswith('meta_')]\n",
    "    \n",
    "    # Convert to numeric and handle missing values\n",
    "    for col in metadata_cols:\n",
    "        slanted[col] = pd.to_numeric(slanted[col], errors='coerce').fillna(0)\n",
    "        unreliable[col] = pd.to_numeric(unreliable[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Calculate pairwise similarities\n",
    "    similarities = []\n",
    "    \n",
    "    for i, (_, slanted_row) in enumerate(slanted.iterrows()):\n",
    "        for j, (_, unreliable_row) in enumerate(unreliable.iterrows()):\n",
    "            \n",
    "            # Create metadata vectors\n",
    "            slanted_meta = [slanted_row[col] for col in metadata_cols]\n",
    "            unreliable_meta = [unreliable_row[col] for col in metadata_cols]\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            similarity = cosine_similarity([slanted_meta], [unreliable_meta])[0][0]\n",
    "            \n",
    "            # Identify matching features\n",
    "            matching_features = []\n",
    "            differing_features = []\n",
    "            \n",
    "            for col in metadata_cols:\n",
    "                slanted_val = slanted_row[col]\n",
    "                unreliable_val = unreliable_row[col]\n",
    "                \n",
    "                feature_name = col.replace('meta_misleading', '').replace('_', ' ').title()\n",
    "                \n",
    "                if slanted_val == unreliable_val and slanted_val == 1:\n",
    "                    matching_features.append(feature_name)\n",
    "                elif slanted_val != unreliable_val and (slanted_val == 1 or unreliable_val == 1):\n",
    "                    differing_features.append(feature_name)\n",
    "            \n",
    "            # Extract tweet content\n",
    "            slanted_tweet = slanted_row['text'].split('[SEP]')[0].strip() if '[SEP]' in str(slanted_row['text']) else str(slanted_row['text'])\n",
    "            unreliable_tweet = unreliable_row['text'].split('[SEP]')[0].strip() if '[SEP]' in str(unreliable_row['text']) else str(unreliable_row['text'])\n",
    "            \n",
    "            similarities.append({\n",
    "                'similarity_score': similarity,\n",
    "                'slanted_content': slanted_tweet,\n",
    "                'unreliable_content': unreliable_tweet,\n",
    "                'matching_features': matching_features,\n",
    "                'differing_features': differing_features,\n",
    "                'num_matching': len(matching_features),\n",
    "                'num_differing': len(differing_features),\n",
    "            })\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    similarities.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "    \n",
    "    print(f\"Similarity Analysis Results:\")\n",
    "    print(f\"  Total pairs analyzed: {len(similarities)}\")\n",
    "    print(f\"  Highest similarity: {similarities[0]['similarity_score']:.3f}\")\n",
    "    print(f\"  Average similarity: {np.mean([s['similarity_score'] for s in similarities]):.3f}\")\n",
    "    print(f\"  Median similarity: {np.median([s['similarity_score'] for s in similarities]):.3f}\")\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f500a",
   "metadata": {},
   "source": [
    "## Export Results for Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f32f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_analysis_results():\n",
    "    \"\"\"\n",
    "    Export analysis results to text files in metadata_analysis_results/ folder for inclusion in thesis.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nExporting Analysis Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"metadata_analysis_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Created output directory: {output_dir}/\")\n",
    "    \n",
    "    # Perform analyses\n",
    "    distribution_results = analyze_metadata_distribution()\n",
    "    similarity_results = find_similar_examples()\n",
    "    \n",
    "    # Export metadata distribution analysis\n",
    "    with open(f\"{output_dir}/metadata_distribution_analysis.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"METADATA FEATURE DISTRIBUTION ANALYSIS\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Overall Feature Distribution:\\n\")\n",
    "        for feature, values in distribution_results['overall_distribution'].items():\n",
    "            active_count = values.get(1.0, 0)\n",
    "            total_count = sum(values.values())\n",
    "            percentage = (active_count / total_count) * 100\n",
    "            feature_short = feature.replace('meta_misleading', '')\n",
    "            f.write(f\"  {feature_short}: {active_count}/{total_count} ({percentage:.1f}%)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nCategory-specific Rates:\\n\")\n",
    "        for category, data in distribution_results['category_analysis'].items():\n",
    "            f.write(f\"\\n{category} (n={data['sample_count']}):\\n\")\n",
    "            for feature, stats in data['feature_rates'].items():\n",
    "                feature_short = feature.replace('meta_misleading', '')\n",
    "                f.write(f\"  {feature_short}: {stats['count']}/{data['sample_count']} ({stats['rate']:.1f}%)\\n\")\n",
    "        \n",
    "        if distribution_results['signal_overlap']:\n",
    "            f.write(f\"\\nSlanted vs Unreliable Source Overlap:\\n\")\n",
    "            for feature, overlap_data in distribution_results['signal_overlap'].items():\n",
    "                feature_short = feature.replace('meta_misleading', '')\n",
    "                f.write(f\"  {feature_short}:\\n\")\n",
    "                f.write(f\"    Slanted: {overlap_data['slanted_rate']:.1f}%\\n\")\n",
    "                f.write(f\"    Unreliable: {overlap_data['unreliable_rate']:.1f}%\\n\")\n",
    "                f.write(f\"    Overlap Score: {overlap_data['overlap_score']:.1f}%\\n\")\n",
    "    \n",
    "    print(f\"Saved: {output_dir}/metadata_distribution_analysis.txt\")\n",
    "    \n",
    "    # Export top similar examples\n",
    "    if similarity_results:\n",
    "        with open(f\"{output_dir}/similar_examples_analysis.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"SIMILAR EXAMPLES: SLANTED VS UNRELIABLE SOURCE\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Analysis Summary:\\n\")\n",
    "            f.write(f\"  Total pairs analyzed: {len(similarity_results)}\\n\")\n",
    "            f.write(f\"  Highest similarity: {similarity_results[0]['similarity_score']:.3f}\\n\")\n",
    "            f.write(f\"  Average similarity: {np.mean([s['similarity_score'] for s in similarity_results]):.3f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Top 5 Most Similar Examples:\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            \n",
    "            for i, pair in enumerate(similarity_results[:5], 1):\n",
    "                f.write(f\"\\nExample {i} (Similarity: {pair['similarity_score']:.3f})\\n\")\n",
    "                f.write(f\"Slanted Content:\\n  {pair['slanted_content'][:200]}...\\n\")\n",
    "                f.write(f\"Unreliable Content:\\n  {pair['unreliable_content'][:200]}...\\n\")\n",
    "                f.write(f\"Matching Features ({pair['num_matching']}): {', '.join(pair['matching_features'])}\\n\")\n",
    "                f.write(f\"Differing Features ({pair['num_differing']}): {', '.join(pair['differing_features'])}\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        print(f\"Saved: {output_dir}/similar_examples_analysis.txt\")\n",
    "        \n",
    "        # Save detailed similarity results as CSV\n",
    "        similarity_df = pd.DataFrame(similarity_results[:20])  # Top 20\n",
    "        similarity_df.to_csv(f\"{output_dir}/top_similar_examples.csv\", index=False)\n",
    "        print(f\"Saved: {output_dir}/top_similar_examples.csv\")\n",
    "    \n",
    "    # Export summary statistics for thesis\n",
    "    with open(f\"{output_dir}/thesis_summary_statistics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"SUMMARY STATISTICS FOR THESIS\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Key Findings:\\n\")\n",
    "        \n",
    "        # Key overlap statistics\n",
    "        if distribution_results['signal_overlap']:\n",
    "            missing_context = distribution_results['signal_overlap'].get('meta_misleadingMissingImportantContext', {})\n",
    "            if missing_context:\n",
    "                f.write(f\"1. Missing Important Context overlap:\\n\")\n",
    "                f.write(f\"   - Slanted: {missing_context['slanted_rate']:.1f}%\\n\")\n",
    "                f.write(f\"   - Unreliable Source: {missing_context['unreliable_rate']:.1f}%\\n\")\n",
    "                f.write(f\"   - Demonstrates substantial overlap in metadata signals\\n\\n\")\n",
    "        \n",
    "        # Similarity findings\n",
    "        if similarity_results:\n",
    "            high_similarity_count = sum(1 for s in similarity_results if s['similarity_score'] > 0.8)\n",
    "            f.write(f\"2. Category Similarity Analysis:\\n\")\n",
    "            f.write(f\"   - {high_similarity_count}/{len(similarity_results)} pairs with >80% similarity\\n\")\n",
    "            f.write(f\"   - Highest similarity score: {similarity_results[0]['similarity_score']:.3f}\\n\")\n",
    "            f.write(f\"   - Average similarity: {np.mean([s['similarity_score'] for s in similarity_results]):.3f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"3. Implications:\\n\")\n",
    "        f.write(\"   - Metadata enhancement failed due to overlapping signal patterns\\n\")\n",
    "        f.write(\"   - Traditional text-only classification may be more effective\\n\")\n",
    "        f.write(\"   - Need for more discriminative metadata features\\n\")\n",
    "    \n",
    "    print(\"Saved: thesis_summary_statistics.txt\")\n",
    "    print(\"\\nAll analysis results exported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389e725",
   "metadata": {},
   "source": [
    "## Execute Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1819c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata Analysis and Category Similarity Study\n",
      "Bachelor Thesis - Enhanced Text Classification Analysis\n",
      "======================================================================\n",
      "\n",
      "Exporting Analysis Results\n",
      "============================================================\n",
      "Created output directory: metadata_analysis_results/\n",
      "Metadata Feature Distribution Analysis\n",
      "============================================================\n",
      "Overall Metadata Feature Distribution:\n",
      "  meta_misleadingUnverifiedClaimAsFact: 100/331 (30.2%)\n",
      "  meta_misleadingMissingImportantContext: 179/331 (54.1%)\n",
      "  meta_misleadingFactualError: 168/331 (50.8%)\n",
      "  meta_misleadingOutdatedInformation: 46/331 (13.9%)\n",
      "  meta_misleadingManipulatedMedia: 49/331 (14.8%)\n",
      "  meta_misleadingSatire: 30/331 (9.1%)\n",
      "\n",
      "Category-specific Analysis:\n",
      "\n",
      "false (n=80):\n",
      "  UnverifiedClaimAsFact: 18/80 (22.5%)\n",
      "  MissingImportantContext: 27/80 (33.8%)\n",
      "  FactualError: 28/80 (35.0%)\n",
      "  OutdatedInformation: 7/80 (8.8%)\n",
      "  ManipulatedMedia: 40/80 (50.0%)\n",
      "  Satire: 16/80 (20.0%)\n",
      "\n",
      "repurposed (n=90):\n",
      "  UnverifiedClaimAsFact: 31/90 (34.4%)\n",
      "  MissingImportantContext: 46/90 (51.1%)\n",
      "  FactualError: 53/90 (58.9%)\n",
      "  OutdatedInformation: 20/90 (22.2%)\n",
      "  ManipulatedMedia: 6/90 (6.7%)\n",
      "  Satire: 7/90 (7.8%)\n",
      "\n",
      "decorative (n=73):\n",
      "  UnverifiedClaimAsFact: 23/73 (31.5%)\n",
      "  MissingImportantContext: 41/73 (56.2%)\n",
      "  FactualError: 39/73 (53.4%)\n",
      "  OutdatedInformation: 10/73 (13.7%)\n",
      "  ManipulatedMedia: 2/73 (2.7%)\n",
      "  Satire: 3/73 (4.1%)\n",
      "\n",
      "slanted (n=71):\n",
      "  UnverifiedClaimAsFact: 21/71 (29.6%)\n",
      "  MissingImportantContext: 54/71 (76.1%)\n",
      "  FactualError: 38/71 (53.5%)\n",
      "  OutdatedInformation: 6/71 (8.5%)\n",
      "  ManipulatedMedia: 1/71 (1.4%)\n",
      "  Satire: 4/71 (5.6%)\n",
      "\n",
      "unreliable source (n=17):\n",
      "  UnverifiedClaimAsFact: 7/17 (41.2%)\n",
      "  MissingImportantContext: 11/17 (64.7%)\n",
      "  FactualError: 10/17 (58.8%)\n",
      "  OutdatedInformation: 3/17 (17.6%)\n",
      "  ManipulatedMedia: 0/17 (0.0%)\n",
      "  Satire: 0/17 (0.0%)\n",
      "\n",
      "Overlap Analysis: Slanted vs Unreliable Source\n",
      "  UnverifiedClaimAsFact:\n",
      "    Slanted: 29.6% | Unreliable: 41.2% | Overlap: 29.6%\n",
      "  MissingImportantContext:\n",
      "    Slanted: 76.1% | Unreliable: 64.7% | Overlap: 64.7%\n",
      "  FactualError:\n",
      "    Slanted: 53.5% | Unreliable: 58.8% | Overlap: 53.5%\n",
      "  OutdatedInformation:\n",
      "    Slanted: 8.5% | Unreliable: 17.6% | Overlap: 8.5%\n",
      "  ManipulatedMedia:\n",
      "    Slanted: 1.4% | Unreliable: 0.0% | Overlap: 0.0%\n",
      "  Satire:\n",
      "    Slanted: 5.6% | Unreliable: 0.0% | Overlap: 0.0%\n",
      "\n",
      "Similarity Analysis: Slanted vs Unreliable Source\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 67 slanted vs 16 unreliable source examples\n",
      "Similarity Analysis Results:\n",
      "  Total pairs analyzed: 1072\n",
      "  Highest similarity: 1.000\n",
      "  Average similarity: 1.000\n",
      "  Median similarity: 1.000\n",
      "Saved: metadata_analysis_results/metadata_distribution_analysis.txt\n",
      "Saved: metadata_analysis_results/similar_examples_analysis.txt\n",
      "Saved: metadata_analysis_results/top_similar_examples.csv\n",
      "Saved: thesis_summary_statistics.txt\n",
      "\n",
      "All analysis results exported successfully.\n",
      "\n",
      "Analysis completed successfully.\n",
      "Check the metadata_analysis_results/ folder for thesis inclusion files.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Execute complete metadata analysis and similarity study.\n",
    "    Results are saved to text files for thesis inclusion.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Metadata Analysis and Category Similarity Study\")\n",
    "    print(\"Bachelor Thesis - Enhanced Text Classification Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        export_analysis_results()\n",
    "        print(\"\\nAnalysis completed successfully.\")\n",
    "        print(\"Check the metadata_analysis_results/ folder for thesis inclusion files.\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required data file not found - {e}\")\n",
    "        print(\"Ensure enhanced_dataset/ directory contains the required CSV files.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {e}\")\n",
    "        print(\"Check data format and file paths.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
