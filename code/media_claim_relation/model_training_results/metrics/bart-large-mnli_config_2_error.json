{
  "model_name": "facebook/bart-large-mnli",
  "run_name": "bart-large-mnli_config_2",
  "config_id": 2,
  "hyperparameters": {
    "config_id": 2,
    "learning_rate": 1e-05,
    "batch_size": 1,
    "epochs": 2,
    "max_length": 128,
    "weight_decay": 0.01,
    "gradient_accumulation_steps": 4
  },
  "error": "Error(s) in loading state_dict for BartForSequenceClassification:\n\tsize mismatch for classification_head.out_proj.weight: copying a param with shape torch.Size([3, 1024]) from checkpoint, the shape in current model is torch.Size([5, 1024]).\n\tsize mismatch for classification_head.out_proj.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([5]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
  "error_type": "RuntimeError",
  "accuracy": null,
  "f1_macro": null
}