model_name,run_name,config_id,hyperparameters,accuracy,f1_macro,f1_weighted,precision_macro,recall_macro,train_time,train_loss,f1_decorative,f1_false,f1_repurposed,f1_slanted,f1_unreliable source
roberta-large,roberta-large_config_1,1,"{'config_id': 1, 'learning_rate': 0.0001, 'batch_size': 2, 'epochs': 2, 'max_length': 512, 'weight_decay': 0.01, 'gradient_accumulation_steps': 2}",0.23880597014925373,0.07710843373493977,0.09206977162380867,0.04776119402985075,0.2,90.4413,1.6460909679018219,0.0,0.3855421686746988,0.0,0.0,0.0
roberta-large,roberta-large_config_2,2,"{'config_id': 2, 'learning_rate': 3e-05, 'batch_size': 1, 'epochs': 3, 'max_length': 256, 'weight_decay': 0.01, 'gradient_accumulation_steps': 4}",0.5522388059701493,0.4541798941798942,0.5430940535418147,0.45392156862745103,0.46416666666666667,164.5245,1.1792108461870785,0.5185185185185185,0.6666666666666666,0.6857142857142857,0.4,0.0
roberta-large,roberta-large_config_3,3,"{'config_id': 3, 'learning_rate': 3e-05, 'batch_size': 1, 'epochs': 2, 'max_length': 512, 'weight_decay': 0.01, 'gradient_accumulation_steps': 4}",0.3283582089552239,0.17795093795093794,0.2204647756886563,0.327683615819209,0.25357142857142856,123.2841,1.562236936468827,0.0,0.2222222222222222,0.4675324675324675,0.2,0.0
