# 📊 COMPREHENSIVE MODEL PERFORMANCE REPORT
Generated on: 2025-06-03 09:34:29

## 🎯 Executive Summary
- **Total Models Evaluated**: 24
- **Unique Model Types**: 8
- **Best Model**: roberta-large
- **Best F1-Macro Score**: 0.4542
- **Best Accuracy**: 0.5522

## 📈 Performance Statistics
### F1-Macro Scores
- Mean: 0.2074 ± 0.1084
- Range: 0.0691 - 0.4542

### Accuracy Scores
- Mean: 0.3097 ± 0.0893
- Range: 0.2090 - 0.5522

## 🏆 Top 10 Models
 1. **roberta-large** (Config 2)
    - F1-Macro: 0.4542
    - Accuracy: 0.5522
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 256

 2. **distilbert-base-uncased** (Config 2)
    - F1-Macro: 0.3959
    - Accuracy: 0.4925
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 256

 3. **Llama-3.2-1B-Instruct** (Config 2)
    - F1-Macro: 0.3339
    - Accuracy: 0.3284
    - Learning Rate: 1e-05
    - Batch Size: 1
    - Max Length: 512

 4. **roberta-base** (Config 2)
    - F1-Macro: 0.3322
    - Accuracy: 0.4179
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 256

 5. **bert-base-uncased** (Config 3)
    - F1-Macro: 0.3203
    - Accuracy: 0.4179
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 512

 6. **bert-base-uncased** (Config 2)
    - F1-Macro: 0.2824
    - Accuracy: 0.3731
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 256

 7. **Llama-3.2-1B-Instruct** (Config 1)
    - F1-Macro: 0.2801
    - Accuracy: 0.3433
    - Learning Rate: 1e-05
    - Batch Size: 1
    - Max Length: 512

 8. **distilbert-base-uncased** (Config 3)
    - F1-Macro: 0.2713
    - Accuracy: 0.3433
    - Learning Rate: 3e-05
    - Batch Size: 1
    - Max Length: 512

 9. **DialoGPT-medium** (Config 1)
    - F1-Macro: 0.2287
    - Accuracy: 0.2687
    - Learning Rate: 1e-05
    - Batch Size: 2
    - Max Length: 384

10. **bert-base-uncased** (Config 1)
    - F1-Macro: 0.2281
    - Accuracy: 0.3284
    - Learning Rate: 0.0001
    - Batch Size: 2
    - Max Length: 512

## 🔬 Model Type Analysis
### DialoGPT-medium
- Configurations tested: 3.0
- Average F1-Macro: 0.2226 ± 0.0091
- Best F1-Macro: 0.2287
- Best Accuracy: 0.2687

### Llama-3.2-1B-Instruct
- Configurations tested: 3.0
- Average F1-Macro: 0.2677 ± 0.0732
- Best F1-Macro: 0.3339
- Best Accuracy: 0.3433

### bert-base-uncased
- Configurations tested: 3.0
- Average F1-Macro: 0.2770 ± 0.0463
- Best F1-Macro: 0.3203
- Best Accuracy: 0.4179

### deberta-v3-base
- Configurations tested: 3.0
- Average F1-Macro: 0.1197 ± 0.0256
- Best F1-Macro: 0.1457
- Best Accuracy: 0.2388

### deberta-v3-large
- Configurations tested: 3.0
- Average F1-Macro: 0.1119 ± 0.0268
- Best F1-Macro: 0.1383
- Best Accuracy: 0.2985

### distilbert-base-uncased
- Configurations tested: 3.0
- Average F1-Macro: 0.2454 ± 0.1649
- Best F1-Macro: 0.3959
- Best Accuracy: 0.4925

### roberta-base
- Configurations tested: 3.0
- Average F1-Macro: 0.1784 ± 0.1342
- Best F1-Macro: 0.3322
- Best Accuracy: 0.4179

### roberta-large
- Configurations tested: 3.0
- Average F1-Macro: 0.2364 ± 0.1952
- Best F1-Macro: 0.4542
- Best Accuracy: 0.5522

## ⚙️ Hyperparameter Analysis
### Learning Rate Impact
- **1e-05**: 0.1917 ± 0.0882 (n=8.0)
- **2e-05**: 0.2122 ± nan (n=1.0)
- **3e-05**: 0.2520 ± 0.1186 (n=11.0)
- **0.0001**: 0.1148 ± 0.0758 (n=4.0)

### Max Length Impact
- **256**: 0.2654 ± 0.1217 (n=8.0)
- **384**: 0.2278 ± 0.0013 (n=2.0)
- **512**: 0.1807 ± 0.1007 (n=12.0)
- **1024**: 0.1152 ± 0.0431 (n=2.0)

## 🏷️ Label Information
### Class Labels
- 0: decorative
- 1: false
- 2: repurposed
- 3: slanted
- 4: unreliable source

## 💡 Recommendations
1. **Use roberta-large** as your primary model
   - Model path: `model_training_results/models/roberta-large_config_2_best`
   - Tokenizer path: `model_training_results/tokenizers/roberta-large_config_2`
2. **Optimal Learning Rate**: 3e-05 (average performance)
3. **Optimal Max Length**: 256
4. **Consider Ensemble**: Top performing model types are roberta-large, distilbert-base-uncased, Llama-3.2-1B-Instruct

---
*Report generated by Model Comparison Analysis*